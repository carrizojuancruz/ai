---
description: How to add new prompts to the centralized prompt system and ensure they're tested
alwaysApply: false
---
# Adding New Prompts to the System

## üö® Only Add Actual LLM Prompts
- Do NOT add UI strings, error messages, or welcome text that never reaches an LLM.
- ONLY add prompts that are sent to language models.

## üìù Steps
1) Choose the right module  
| File | When to Use |
|------|-------------|
| `app/services/llm/agent_prompts.py` | Agent system prompts (supervisor, finance, wealth, goal, guest, finance capture) |
| `app/services/llm/memory_prompts.py` | Memory prompts (hotpath, episodic, icebreaker, summarizer, profile sync) |
| `app/services/llm/utility_prompts.py` | Utility prompts (titles, summarizer, welcome) |
| `app/services/llm/onboarding_prompts.py` | Onboarding extraction prompts |

2) Define the prompt in the module (use `_LOCAL` suffix for constants or a builder function for dynamic variants). Keep format rules: `##` headers, `- ` bullets, `---` horizontal rules; no emojis or tabs.

3) Register in `PromptLoader._register_defaults()` inside `app/services/llm/prompt_loader.py`, mapping the prompt name to a loader function/callable.

4) Add an entry to `tests/supervisor_prompts/prompt_specs.json` with the correct module and symbol. For builder functions, set `"callable": true` and provide default parameter values; for constants, set `"callable": false`.
   Example:
```json
{
  "name": "new_prompt",
  "module": "app.services.llm.agent_prompts",
  "symbol": "NEW_PROMPT_LOCAL",
  "callable": false,
  "type": "constant",
  "parameters": [],
  "prompt_preview": "Your prompt text here...",
  "description": "Brief description of what this prompt does"
}
```

5) Test
```bash
poetry run pytest tests/supervisor_prompts/static/ -v
python -c "from app.services.llm.prompt_loader import prompt_loader; print(prompt_loader.load('new_prompt'))"
```

## ‚úÖ Validation Rules
- UTF-8 only; no `\u` escapes
- No tabs or trailing spaces
- Headers use `##`; bullets use `- ` or `---`; no emojis

## üö´ Common Mistakes
- Adding non-LLM strings
- Not wiring `_register_defaults` in `PromptLoader`
- Missing/incorrect `prompt_specs.json` entry (module/symbol/callable/params)
- Wrong format placeholders or missing defaults