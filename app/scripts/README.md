## Memory Dump CLI

Utility for inspecting and managing user memories stored in Amazon S3 Vectors via the `S3VectorsStore`.

### Prerequisites

- The app must run inside Docker Compose and use Poetry (as in this repo).
- AWS credentials and required env vars available to the running container:
  - `AWS_REGION` (or `AWS_DEFAULT_REGION`)
  - `S3V_BUCKET`
  - `S3V_INDEX_MEMORY`

### Basic usage

Run all commands through Poetry inside the container:

```bash
docker compose exec app poetry run python -m app.scripts.dump_memories --help
```

On Windows/PowerShell, to pretty-print JSON outputs:

```powershell
docker compose exec app poetry run python -m app.scripts.dump_memories --help | ConvertFrom-Json | ConvertTo-Json -Depth 100
```

Common flags:

- `--user-id <UUID|STRING>`: Required for most operations. Use "system" for template operations. The user namespace (ns_0).
- `--type semantic|episodic|supervisor_procedural|finance_contracts`: Memory type (ns_1). Default: `semantic`.
- `--query "..."`: Semantic query text (required for searches).
- `--category <Category>`: Optional category filter (e.g., `Finance`, `Personal`).
- `--limit <N>` / `--offset <N>`: Paging.
- `--get-key <KEY>`: Fetch a single memory by key.
- `--delete-key <KEY>`: Delete a single memory by key.
- `--delete-all`: Delete all memories for the user and type.
- `--put-summary <TEXT>`: Create a single memory with the provided summary.
- `--put-category <Category>`: Category for the inserted memory (default: `Other`).
- `--put-key <KEY>`: Optional key for single insert; autogenerated if omitted.
- `--put-file <PATH>`: Bulk insert memories from a JSONL file (one JSON object per line).
- `--seed-contracts`: Seed finance chart contracts into the store.
- `--list-contracts`: List all finance contracts in the store.
- `--seed-templates`: Seed finance procedural templates into the store (no user id required).
- `--list-templates`: List all finance procedural templates in the store (no user id required).

### Examples

#### 1) Semantic search (top 10)

```bash
docker compose exec app poetry run python -m app.scripts.dump_memories \
  --user-id <USER_ID> \
  --type semantic \
  --query "profile" \
  --limit 10
```

PowerShell pretty-print:

```powershell
docker compose exec app poetry run python -m app.scripts.dump_memories `
  --user-id <USER_ID> `
  --type semantic `
  --query "profile" `
  --limit 10 |
  ConvertFrom-Json | ConvertTo-Json -Depth 100
```

#### 2) Semantic search filtered by category

```bash
docker compose exec app poetry run python -m app.scripts.dump_memories \
  --user-id <USER_ID> \
  --type semantic \
  --category Personal \
  --query "name" \
  --limit 5
```

PowerShell pretty-print:

```powershell
docker compose exec app poetry run python -m app.scripts.dump_memories `
  --user-id <USER_ID> `
  --type semantic `
  --category Personal `
  --query "name" `
  --limit 5 |
  ConvertFrom-Json | ConvertTo-Json -Depth 100
```

#### 3) Episodic search

```bash
docker compose exec app poetry run python -m app.scripts.dump_memories \
  --user-id <USER_ID> \
  --type episodic \
  --query "recent" \
  --limit 5
```

PowerShell pretty-print:

```powershell
docker compose exec app poetry run python -m app.scripts.dump_memories `
  --user-id <USER_ID> `
  --type episodic `
  --query "recent" `
  --limit 5 |
  ConvertFrom-Json | ConvertTo-Json -Depth 100
```

#### 4) Get a single memory by key

```bash
docker compose exec app poetry run python -m app.scripts.dump_memories \
  --user-id <USER_ID> \
  --type semantic \
  --get-key <KEY>
```

PowerShell pretty-print:

```powershell
docker compose exec app poetry run python -m app.scripts.dump_memories `
  --user-id <USER_ID> `
  --type semantic `
  --get-key <KEY> |
  ConvertFrom-Json | ConvertTo-Json -Depth 100
```

#### 5) Delete a memory by key

```bash
docker compose exec app poetry run python -m app.scripts.dump_memories \
  --user-id <USER_ID> \
  --type semantic \
  --delete-key <KEY>
```

PowerShell pretty-print:

```powershell
docker compose exec app poetry run python -m app.scripts.dump_memories `
  --user-id <USER_ID> `
  --type semantic `
  --delete-key <KEY> |
  ConvertFrom-Json | ConvertTo-Json -Depth 100
```

#### 6) Delete all memories for a user and type

```bash
docker compose exec app poetry run python -m app.scripts.dump_memories \
  --user-id <USER_ID> \
  --type semantic \
  --delete-all
```

PowerShell pretty-print:

```powershell
docker compose exec app poetry run python -m app.scripts.dump_memories `
  --user-id <USER_ID> `
  --type semantic `
  --delete-all |
  ConvertFrom-Json | ConvertTo-Json -Depth 100
```

**Note**: This will delete ALL memories of the specified type for the user. Use with caution!

#### 7) Create a single memory

```bash
docker compose exec app poetry run python -m app.scripts.dump_memories \
  --user-id <USER_ID> \
  --type semantic \
  --put-summary "User likes sushi." \
  --put-category Personal \
  --put-key optional_key
```

PowerShell pretty-print:

```powershell
docker compose exec app poetry run python -m app.scripts.dump_memories `
  --user-id <USER_ID> `
  --type semantic `
  --put-summary "User likes sushi." `
  --put-category Personal `
  --put-key optional_key |
  ConvertFrom-Json | ConvertTo-Json -Depth 100
```

#### 8) Bulk insert from JSONL

- File format: one JSON per line with fields: `summary` (string), `category` (string, optional), `key` (string, optional)

Example file (memories.jsonl):

```json
{"summary": "User's name is Joaquin.", "category": "Personal"}
{"summary": "User prefers notifications off after 9pm.", "category": "Personal", "key": "pref_9pm"}
```

Command:

```bash
docker compose exec app poetry run python -m app.scripts.dump_memories \
  --user-id <USER_ID> \
  --type semantic \
  --put-file /app/data/memories.jsonl
```

PowerShell pretty-print:

```powershell
docker compose exec app poetry run python -m app.scripts.dump_memories `
  --user-id <USER_ID> `
  --type semantic `
  --put-file /app/data/memories.jsonl |
  ConvertFrom-Json | ConvertTo-Json -Depth 100
```

#### 9) Seed Finance Contracts

```bash
docker compose exec app poetry run python -m app.scripts.dump_memories \
  --seed-contracts
```

PowerShell pretty-print:

```powershell
docker compose exec app poetry run python -m app.scripts.dump_memories `
  --seed-contracts |
  ConvertFrom-Json | ConvertTo-Json -Depth 100
```

#### 10) List Finance Contracts

```bash
docker compose exec app poetry run python -m app.scripts.dump_memories \
  --list-contracts
```

PowerShell pretty-print:

```powershell
docker compose exec app poetry run python -m app.scripts.dump_memories `
  --list-contracts |
  ConvertFrom-Json | ConvertTo-Json -Depth 100
```

#### 11) Seed Finance Procedural Templates

```bash
docker compose exec app poetry run python -m app.scripts.dump_memories \
  --user-id "system" \
  --seed-templates
```

PowerShell pretty-print:

```powershell
docker compose exec app poetry run python -m app.scripts.dump_memories `
  --user-id "system" `
  --seed-templates |
  ConvertFrom-Json | ConvertTo-Json -Depth 100
```

#### 12) List Finance Procedural Templates

```bash
docker compose exec app poetry run python -m app.scripts.dump_memories \
  --list-templates
```

PowerShell pretty-print:

```powershell
docker compose exec app poetry run python -m app.scripts.dump_memories `
  --list-templates |
  ConvertFrom-Json | ConvertTo-Json -Depth 100
```

### Notes

- The tool prints strict JSON to stdout. If you need pretty output:

- **Delete-all output format**: When using `--delete-all`, the response includes:
  - `deleted_count`: Number of successfully deleted memories
  - `failed_count`: Number of memories that failed to delete
  - `total_found`: Total number of memories found before deletion

  - PowerShell:

  ```powershell
  docker compose exec app poetry run python -m app.scripts.dump_memories `
    --user-id <USER_ID> ` --type semantic ` --query "profile" ` --limit 5 |
    ConvertFrom-Json | ConvertTo-Json -Depth 100
  ```

  - bash with `jq`:

  ```bash
  docker compose exec app poetry run python -m app.scripts.dump_memories \
    --user-id <USER_ID> --type semantic --query "profile" --limit 5 | jq .
  ```

- The `user-id` and `type` together form the memory namespace.
- The store uses `value_json` as non-filterable metadata in S3 Vectors and keeps filterable fields like `ns_0`, `ns_1`, `category`, `doc_key`, and `is_indexed` for querying.


